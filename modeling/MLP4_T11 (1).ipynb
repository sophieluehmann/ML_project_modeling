{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb92020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kaggle.cli\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3b3022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2701b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426880, 26)\n",
      "id              426880\n",
      "url             426880\n",
      "region          426880\n",
      "region_url      426880\n",
      "price           426880\n",
      "year            425675\n",
      "manufacturer    409234\n",
      "model           421603\n",
      "condition       252776\n",
      "cylinders       249202\n",
      "fuel            423867\n",
      "odometer        422480\n",
      "title_status    418638\n",
      "transmission    424324\n",
      "VIN             265838\n",
      "drive           296313\n",
      "size            120519\n",
      "type            334022\n",
      "paint_color     296677\n",
      "image_url       426812\n",
      "description     426810\n",
      "county               0\n",
      "state           426880\n",
      "lat             420331\n",
      "long            420331\n",
      "posting_date    426812\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_A = pd.read_csv('C:/Users/Gabriel/Downloads/vehicles.csv') # file name\n",
    "print(data_A.shape)\n",
    "print(data_A.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff05a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp/ipykernel_25516/3755468815.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data_A = data_A.drop(field,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region          0\n",
      "price           0\n",
      "year            0\n",
      "manufacturer    0\n",
      "model           0\n",
      "condition       0\n",
      "fuel            0\n",
      "odometer        0\n",
      "transmission    0\n",
      "drive           0\n",
      "size            0\n",
      "type            0\n",
      "paint_color     0\n",
      "state           0\n",
      "dtype: int64\n",
      "region          80961\n",
      "price           80961\n",
      "year            80961\n",
      "manufacturer    80961\n",
      "model           80961\n",
      "condition       80961\n",
      "fuel            80961\n",
      "odometer        80961\n",
      "transmission    80961\n",
      "drive           80961\n",
      "size            80961\n",
      "type            80961\n",
      "paint_color     80961\n",
      "state           80961\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80961 entries, 31 to 426836\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   region        80961 non-null  object \n",
      " 1   price         80961 non-null  int64  \n",
      " 2   year          80961 non-null  float64\n",
      " 3   manufacturer  80961 non-null  object \n",
      " 4   model         80961 non-null  object \n",
      " 5   condition     80961 non-null  object \n",
      " 6   fuel          80961 non-null  object \n",
      " 7   odometer      80961 non-null  float64\n",
      " 8   transmission  80961 non-null  object \n",
      " 9   drive         80961 non-null  object \n",
      " 10  size          80961 non-null  object \n",
      " 11  type          80961 non-null  object \n",
      " 12  paint_color   80961 non-null  object \n",
      " 13  state         80961 non-null  object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "drop = {'id', 'url', 'cylinders','region_url', 'image_url', 'county', 'posting_date', 'description', 'title_status','VIN','lat','long'}\n",
    "\n",
    "for field in drop:\n",
    "    if field in data_A.columns:\n",
    "        data_A = data_A.drop(field,1)\n",
    "\n",
    "data_A = data_A.dropna()\n",
    "\n",
    "print(data_A.isnull().sum()) # see what is missing from data\n",
    "print(data_A.count())\n",
    "\n",
    "data_A.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e13f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "catgFeatures = ['region', 'manufacturer', 'model', 'condition', \n",
    "                 'fuel', 'odometer', 'transmission', \n",
    "                'drive', 'size', 'type', 'paint_color', 'state']\n",
    "\n",
    "#Categorical variable encoding\n",
    "for feature in catgFeatures:\n",
    "    featureData = data_A[feature]\n",
    "    featuresEncoded = LabelEncoder().fit_transform(featureData)\n",
    "    data_A[feature] = featuresEncoded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4775cf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "MinMaxScaler()\n",
      "MinMaxScaler()\n",
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data_A.values\n",
    "y = data_A['price'].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "print(scaler_x.fit(X))\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_y.fit(y))\n",
    "x1scale=scaler_x.transform(X)\n",
    "y1scale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9269b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe16f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                180       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293\n",
      "Trainable params: 293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#data_A input dimension = 14\n",
    "model.add(Dense(12, input_dim=14, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31b24bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=rms, loss='mse',  metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c1179a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "972/972 [==============================] - 5s 3ms/step - loss: 6.1128e-05 - mse: 6.1128e-05 - mae: 0.0025 - val_loss: 6.5724e-08 - val_mse: 6.5724e-08 - val_mae: 1.5689e-04\n",
      "Epoch 2/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2580e-05 - mse: 2.2580e-05 - mae: 2.1701e-04 - val_loss: 3.7975e-08 - val_mse: 3.7975e-08 - val_mae: 1.7576e-04\n",
      "Epoch 3/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2552e-05 - mse: 2.2552e-05 - mae: 1.9680e-04 - val_loss: 3.2036e-08 - val_mse: 3.2036e-08 - val_mae: 1.7239e-04\n",
      "Epoch 4/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2547e-05 - mse: 2.2547e-05 - mae: 1.8409e-04 - val_loss: 3.1059e-08 - val_mse: 3.1059e-08 - val_mae: 1.7390e-04\n",
      "Epoch 5/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2536e-05 - mse: 2.2536e-05 - mae: 1.7242e-04 - val_loss: 3.4191e-08 - val_mse: 3.4191e-08 - val_mae: 1.8170e-04\n",
      "Epoch 6/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2400e-05 - mse: 2.2400e-05 - mae: 1.6436e-04 - val_loss: 2.2542e-08 - val_mse: 2.2542e-08 - val_mae: 1.4959e-04\n",
      "Epoch 7/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2376e-05 - mse: 2.2376e-05 - mae: 1.5956e-04 - val_loss: 2.0781e-08 - val_mse: 2.0781e-08 - val_mae: 1.4398e-04\n",
      "Epoch 8/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2410e-05 - mse: 2.2410e-05 - mae: 1.5769e-04 - val_loss: 2.3199e-08 - val_mse: 2.3199e-08 - val_mae: 1.5161e-04\n",
      "Epoch 9/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2417e-05 - mse: 2.2417e-05 - mae: 1.5956e-04 - val_loss: 1.9854e-08 - val_mse: 1.9854e-08 - val_mae: 1.3915e-04\n",
      "Epoch 10/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2433e-05 - mse: 2.2433e-05 - mae: 1.5959e-04 - val_loss: 1.7095e-10 - val_mse: 1.7095e-10 - val_mae: 3.7404e-06\n",
      "Epoch 11/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2453e-05 - mse: 2.2453e-05 - mae: 1.5923e-04 - val_loss: 1.9996e-08 - val_mse: 1.9996e-08 - val_mae: 1.4065e-04\n",
      "Epoch 12/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2423e-05 - mse: 2.2423e-05 - mae: 1.5633e-04 - val_loss: 2.0493e-08 - val_mse: 2.0493e-08 - val_mae: 1.4305e-04\n",
      "Epoch 13/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2442e-05 - mse: 2.2442e-05 - mae: 1.5589e-04 - val_loss: 2.0394e-08 - val_mse: 2.0394e-08 - val_mae: 1.4266e-04\n",
      "Epoch 14/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2426e-05 - mse: 2.2426e-05 - mae: 1.5160e-04 - val_loss: 1.9059e-08 - val_mse: 1.9059e-08 - val_mae: 1.3741e-04\n",
      "Epoch 15/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2437e-05 - mse: 2.2437e-05 - mae: 1.5802e-04 - val_loss: 2.1405e-08 - val_mse: 2.1405e-08 - val_mae: 1.4613e-04\n",
      "Epoch 16/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2438e-05 - mse: 2.2438e-05 - mae: 1.4424e-04 - val_loss: 1.4452e-08 - val_mse: 1.4452e-08 - val_mae: 1.1906e-04\n",
      "Epoch 17/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2432e-05 - mse: 2.2432e-05 - mae: 1.4352e-04 - val_loss: 1.7314e-08 - val_mse: 1.7314e-08 - val_mae: 1.3133e-04\n",
      "Epoch 18/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2427e-05 - mse: 2.2427e-05 - mae: 1.4730e-04 - val_loss: 1.9848e-08 - val_mse: 1.9848e-08 - val_mae: 1.4076e-04\n",
      "Epoch 19/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2417e-05 - mse: 2.2417e-05 - mae: 1.4849e-04 - val_loss: 1.4288e-08 - val_mse: 1.4288e-08 - val_mae: 1.1907e-04\n",
      "Epoch 20/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2407e-05 - mse: 2.2407e-05 - mae: 1.3603e-04 - val_loss: 2.1603e-08 - val_mse: 2.1603e-08 - val_mae: 1.4681e-04\n",
      "Epoch 21/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2404e-05 - mse: 2.2404e-05 - mae: 1.5131e-04 - val_loss: 1.3913e-08 - val_mse: 1.3913e-08 - val_mae: 1.1743e-04\n",
      "Epoch 22/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2384e-05 - mse: 2.2384e-05 - mae: 1.4160e-04 - val_loss: 2.9504e-10 - val_mse: 2.9504e-10 - val_mae: 4.9354e-06\n",
      "Epoch 23/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2399e-05 - mse: 2.2399e-05 - mae: 1.4536e-04 - val_loss: 1.4148e-08 - val_mse: 1.4148e-08 - val_mae: 1.1884e-04\n",
      "Epoch 24/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2374e-05 - mse: 2.2374e-05 - mae: 1.4742e-04 - val_loss: 1.8549e-08 - val_mse: 1.8549e-08 - val_mae: 1.3614e-04\n",
      "Epoch 25/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2367e-05 - mse: 2.2367e-05 - mae: 1.4562e-04 - val_loss: 3.2351e-08 - val_mse: 3.2351e-08 - val_mae: 1.7976e-04\n",
      "Epoch 26/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2365e-05 - mse: 2.2365e-05 - mae: 1.4098e-04 - val_loss: 2.1851e-08 - val_mse: 2.1851e-08 - val_mae: 1.4769e-04\n",
      "Epoch 27/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2351e-05 - mse: 2.2351e-05 - mae: 1.4119e-04 - val_loss: 1.1943e-08 - val_mse: 1.1943e-08 - val_mae: 1.0905e-04\n",
      "Epoch 28/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2334e-05 - mse: 2.2334e-05 - mae: 1.3598e-04 - val_loss: 9.7051e-10 - val_mse: 9.7051e-10 - val_mae: 3.0398e-05\n",
      "Epoch 29/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2329e-05 - mse: 2.2329e-05 - mae: 1.3275e-04 - val_loss: 4.6987e-11 - val_mse: 4.6987e-11 - val_mae: 2.7892e-06\n",
      "Epoch 30/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2341e-05 - mse: 2.2341e-05 - mae: 1.3693e-04 - val_loss: 4.4800e-08 - val_mse: 4.4800e-08 - val_mae: 2.1135e-04\n",
      "Epoch 31/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2322e-05 - mse: 2.2322e-05 - mae: 1.3957e-04 - val_loss: 1.4528e-08 - val_mse: 1.4528e-08 - val_mae: 1.2035e-04\n",
      "Epoch 32/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2315e-05 - mse: 2.2315e-05 - mae: 1.3238e-04 - val_loss: 1.1991e-08 - val_mse: 1.1991e-08 - val_mae: 1.0922e-04\n",
      "Epoch 33/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2306e-05 - mse: 2.2306e-05 - mae: 1.3357e-04 - val_loss: 8.0160e-09 - val_mse: 8.0160e-09 - val_mae: 8.9071e-05\n",
      "Epoch 34/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2295e-05 - mse: 2.2295e-05 - mae: 1.3299e-04 - val_loss: 1.5589e-08 - val_mse: 1.5589e-08 - val_mae: 1.2351e-04\n",
      "Epoch 35/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2301e-05 - mse: 2.2301e-05 - mae: 1.3467e-04 - val_loss: 1.8131e-08 - val_mse: 1.8131e-08 - val_mae: 1.3439e-04\n",
      "Epoch 36/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2284e-05 - mse: 2.2284e-05 - mae: 1.3646e-04 - val_loss: 2.0362e-08 - val_mse: 2.0362e-08 - val_mae: 1.4127e-04\n",
      "Epoch 37/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2277e-05 - mse: 2.2277e-05 - mae: 1.3583e-04 - val_loss: 1.0301e-08 - val_mse: 1.0301e-08 - val_mae: 1.0096e-04\n",
      "Epoch 38/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2271e-05 - mse: 2.2271e-05 - mae: 1.4032e-04 - val_loss: 3.5700e-09 - val_mse: 3.5700e-09 - val_mae: 5.8243e-05\n",
      "Epoch 39/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2261e-05 - mse: 2.2261e-05 - mae: 1.3575e-04 - val_loss: 1.2262e-08 - val_mse: 1.2262e-08 - val_mae: 1.0997e-04\n",
      "Epoch 40/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2257e-05 - mse: 2.2257e-05 - mae: 1.3357e-04 - val_loss: 1.0167e-08 - val_mse: 1.0167e-08 - val_mae: 1.0008e-04\n",
      "Epoch 41/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2239e-05 - mse: 2.2239e-05 - mae: 1.3463e-04 - val_loss: 1.7348e-08 - val_mse: 1.7348e-08 - val_mae: 1.3144e-04\n",
      "Epoch 42/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2227e-05 - mse: 2.2227e-05 - mae: 1.3475e-04 - val_loss: 1.3756e-08 - val_mse: 1.3756e-08 - val_mae: 1.1701e-04\n",
      "Epoch 43/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2224e-05 - mse: 2.2224e-05 - mae: 1.3352e-04 - val_loss: 1.2839e-08 - val_mse: 1.2839e-08 - val_mae: 1.1259e-04\n",
      "Epoch 44/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2211e-05 - mse: 2.2211e-05 - mae: 1.3808e-04 - val_loss: 3.3216e-08 - val_mse: 3.3216e-08 - val_mae: 1.8209e-04\n",
      "Epoch 45/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2197e-05 - mse: 2.2197e-05 - mae: 1.2782e-04 - val_loss: 8.8532e-09 - val_mse: 8.8532e-09 - val_mae: 9.3426e-05\n",
      "Epoch 46/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2187e-05 - mse: 2.2187e-05 - mae: 1.3313e-04 - val_loss: 1.3626e-08 - val_mse: 1.3626e-08 - val_mae: 1.1652e-04\n",
      "Epoch 47/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2197e-05 - mse: 2.2197e-05 - mae: 1.3166e-04 - val_loss: 1.2028e-08 - val_mse: 1.2028e-08 - val_mae: 1.0941e-04\n",
      "Epoch 48/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2187e-05 - mse: 2.2187e-05 - mae: 1.2774e-04 - val_loss: 2.4881e-10 - val_mse: 2.4881e-10 - val_mae: 1.4499e-05\n",
      "Epoch 49/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2172e-05 - mse: 2.2172e-05 - mae: 1.2802e-04 - val_loss: 1.1887e-10 - val_mse: 1.1887e-10 - val_mae: 3.1898e-06\n",
      "Epoch 50/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2158e-05 - mse: 2.2158e-05 - mae: 1.3374e-04 - val_loss: 1.9020e-08 - val_mse: 1.9020e-08 - val_mae: 1.3760e-04\n",
      "Epoch 51/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2179e-05 - mse: 2.2179e-05 - mae: 1.4131e-04 - val_loss: 1.2165e-08 - val_mse: 1.2165e-08 - val_mae: 1.1003e-04\n",
      "Epoch 52/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2142e-05 - mse: 2.2142e-05 - mae: 1.2664e-04 - val_loss: 1.3782e-08 - val_mse: 1.3782e-08 - val_mae: 1.1713e-04\n",
      "Epoch 53/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2140e-05 - mse: 2.2140e-05 - mae: 1.4623e-04 - val_loss: 1.9395e-08 - val_mse: 1.9395e-08 - val_mae: 1.3922e-04\n",
      "Epoch 54/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2140e-05 - mse: 2.2140e-05 - mae: 1.3666e-04 - val_loss: 1.3604e-08 - val_mse: 1.3604e-08 - val_mae: 1.1646e-04\n",
      "Epoch 55/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2127e-05 - mse: 2.2127e-05 - mae: 1.2800e-04 - val_loss: 1.2257e-08 - val_mse: 1.2257e-08 - val_mae: 1.1007e-04\n",
      "Epoch 56/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2123e-05 - mse: 2.2123e-05 - mae: 1.3763e-04 - val_loss: 7.0387e-08 - val_mse: 7.0387e-08 - val_mae: 2.6520e-04\n",
      "Epoch 57/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2109e-05 - mse: 2.2109e-05 - mae: 1.2763e-04 - val_loss: 6.8669e-09 - val_mse: 6.8669e-09 - val_mae: 8.2645e-05\n",
      "Epoch 58/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2103e-05 - mse: 2.2103e-05 - mae: 1.4172e-04 - val_loss: 1.1169e-08 - val_mse: 1.1169e-08 - val_mae: 1.0548e-04\n",
      "Epoch 59/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2083e-05 - mse: 2.2083e-05 - mae: 1.3212e-04 - val_loss: 5.7840e-09 - val_mse: 5.7840e-09 - val_mae: 7.5809e-05\n",
      "Epoch 60/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2088e-05 - mse: 2.2088e-05 - mae: 1.3614e-04 - val_loss: 4.0639e-11 - val_mse: 4.0639e-11 - val_mae: 2.4954e-06\n",
      "Epoch 61/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2058e-05 - mse: 2.2058e-05 - mae: 1.3143e-04 - val_loss: 1.8399e-08 - val_mse: 1.8399e-08 - val_mae: 1.3548e-04\n",
      "Epoch 62/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2048e-05 - mse: 2.2048e-05 - mae: 1.2636e-04 - val_loss: 4.5661e-11 - val_mse: 4.5661e-11 - val_mae: 2.5088e-06\n",
      "Epoch 63/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2062e-05 - mse: 2.2062e-05 - mae: 1.2497e-04 - val_loss: 1.0637e-08 - val_mse: 1.0637e-08 - val_mae: 1.0293e-04\n",
      "Epoch 64/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2051e-05 - mse: 2.2051e-05 - mae: 1.3077e-04 - val_loss: 6.8595e-10 - val_mse: 6.8595e-10 - val_mae: 2.5450e-05\n",
      "Epoch 65/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2037e-05 - mse: 2.2037e-05 - mae: 1.3422e-04 - val_loss: 2.6962e-09 - val_mse: 2.6962e-09 - val_mae: 5.1491e-05\n",
      "Epoch 66/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2031e-05 - mse: 2.2031e-05 - mae: 1.2952e-04 - val_loss: 1.0474e-08 - val_mse: 1.0474e-08 - val_mae: 1.0201e-04\n",
      "Epoch 67/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2014e-05 - mse: 2.2014e-05 - mae: 1.3154e-04 - val_loss: 1.5409e-08 - val_mse: 1.5409e-08 - val_mae: 1.2397e-04\n",
      "Epoch 68/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2022e-05 - mse: 2.2022e-05 - mae: 1.3449e-04 - val_loss: 2.1451e-09 - val_mse: 2.1451e-09 - val_mae: 4.5181e-05\n",
      "Epoch 69/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1998e-05 - mse: 2.1998e-05 - mae: 1.2816e-04 - val_loss: 1.2749e-08 - val_mse: 1.2749e-08 - val_mae: 1.1213e-04\n",
      "Epoch 70/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2000e-05 - mse: 2.2000e-05 - mae: 1.3011e-04 - val_loss: 8.2703e-09 - val_mse: 8.2703e-09 - val_mae: 9.0601e-05\n",
      "Epoch 71/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1982e-05 - mse: 2.1982e-05 - mae: 1.3252e-04 - val_loss: 1.0539e-08 - val_mse: 1.0539e-08 - val_mae: 1.0193e-04\n",
      "Epoch 72/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1980e-05 - mse: 2.1980e-05 - mae: 1.2767e-04 - val_loss: 9.0094e-09 - val_mse: 9.0094e-09 - val_mae: 9.4176e-05\n",
      "Epoch 73/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1958e-05 - mse: 2.1958e-05 - mae: 1.3114e-04 - val_loss: 1.2746e-08 - val_mse: 1.2746e-08 - val_mae: 1.1246e-04\n",
      "Epoch 74/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1957e-05 - mse: 2.1957e-05 - mae: 1.3210e-04 - val_loss: 1.2079e-08 - val_mse: 1.2079e-08 - val_mae: 1.0920e-04\n",
      "Epoch 75/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1951e-05 - mse: 2.1951e-05 - mae: 1.2857e-04 - val_loss: 3.0145e-07 - val_mse: 3.0145e-07 - val_mae: 5.4898e-04\n",
      "Epoch 76/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1943e-05 - mse: 2.1943e-05 - mae: 1.2647e-04 - val_loss: 7.4359e-09 - val_mse: 7.4359e-09 - val_mae: 8.4958e-05\n",
      "Epoch 77/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1926e-05 - mse: 2.1926e-05 - mae: 1.2495e-04 - val_loss: 1.3474e-08 - val_mse: 1.3474e-08 - val_mae: 1.1561e-04\n",
      "Epoch 78/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1923e-05 - mse: 2.1923e-05 - mae: 1.2696e-04 - val_loss: 2.7276e-10 - val_mse: 2.7276e-10 - val_mae: 1.1790e-05\n",
      "Epoch 79/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1896e-05 - mse: 2.1896e-05 - mae: 1.2571e-04 - val_loss: 5.4081e-09 - val_mse: 5.4081e-09 - val_mae: 7.3069e-05\n",
      "Epoch 80/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1910e-05 - mse: 2.1910e-05 - mae: 1.2866e-04 - val_loss: 8.5198e-08 - val_mse: 8.5198e-08 - val_mae: 2.9141e-04\n",
      "Epoch 81/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1883e-05 - mse: 2.1883e-05 - mae: 1.2115e-04 - val_loss: 1.1706e-08 - val_mse: 1.1706e-08 - val_mae: 1.0786e-04\n",
      "Epoch 82/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1888e-05 - mse: 2.1888e-05 - mae: 1.3337e-04 - val_loss: 1.6386e-08 - val_mse: 1.6386e-08 - val_mae: 1.2785e-04\n",
      "Epoch 83/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1876e-05 - mse: 2.1876e-05 - mae: 1.3956e-04 - val_loss: 9.7524e-09 - val_mse: 9.7524e-09 - val_mae: 9.7968e-05\n",
      "Epoch 84/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1863e-05 - mse: 2.1863e-05 - mae: 1.2920e-04 - val_loss: 3.5725e-10 - val_mse: 3.5725e-10 - val_mae: 1.6071e-05\n",
      "Epoch 85/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1858e-05 - mse: 2.1858e-05 - mae: 1.2605e-04 - val_loss: 9.5747e-09 - val_mse: 9.5747e-09 - val_mae: 9.7591e-05\n",
      "Epoch 86/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1852e-05 - mse: 2.1852e-05 - mae: 1.3075e-04 - val_loss: 1.1144e-08 - val_mse: 1.1144e-08 - val_mae: 1.0546e-04\n",
      "Epoch 87/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1835e-05 - mse: 2.1835e-05 - mae: 1.2580e-04 - val_loss: 2.6865e-08 - val_mse: 2.6865e-08 - val_mae: 1.6378e-04\n",
      "Epoch 88/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1832e-05 - mse: 2.1832e-05 - mae: 1.2664e-04 - val_loss: 4.4746e-11 - val_mse: 4.4746e-11 - val_mae: 2.6629e-06\n",
      "Epoch 89/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1820e-05 - mse: 2.1820e-05 - mae: 1.3384e-04 - val_loss: 1.0448e-08 - val_mse: 1.0448e-08 - val_mae: 1.0210e-04\n",
      "Epoch 90/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1812e-05 - mse: 2.1812e-05 - mae: 1.2830e-04 - val_loss: 1.0792e-08 - val_mse: 1.0792e-08 - val_mae: 1.0371e-04\n",
      "Epoch 91/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1793e-05 - mse: 2.1793e-05 - mae: 1.3603e-04 - val_loss: 1.5179e-08 - val_mse: 1.5179e-08 - val_mae: 1.2308e-04\n",
      "Epoch 92/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1799e-05 - mse: 2.1799e-05 - mae: 1.3656e-04 - val_loss: 1.0339e-08 - val_mse: 1.0339e-08 - val_mae: 1.0144e-04\n",
      "Epoch 93/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1790e-05 - mse: 2.1790e-05 - mae: 1.2191e-04 - val_loss: 8.0721e-09 - val_mse: 8.0721e-09 - val_mae: 8.9614e-05\n",
      "Epoch 94/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1790e-05 - mse: 2.1790e-05 - mae: 1.2165e-04 - val_loss: 1.0800e-08 - val_mse: 1.0800e-08 - val_mae: 1.0367e-04\n",
      "Epoch 95/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1769e-05 - mse: 2.1769e-05 - mae: 1.2655e-04 - val_loss: 8.1358e-09 - val_mse: 8.1358e-09 - val_mae: 9.0118e-05\n",
      "Epoch 96/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1770e-05 - mse: 2.1770e-05 - mae: 1.2585e-04 - val_loss: 9.9630e-09 - val_mse: 9.9630e-09 - val_mae: 9.9723e-05\n",
      "Epoch 97/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1763e-05 - mse: 2.1763e-05 - mae: 1.2361e-04 - val_loss: 1.5620e-08 - val_mse: 1.5620e-08 - val_mae: 1.2487e-04\n",
      "Epoch 98/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1761e-05 - mse: 2.1761e-05 - mae: 1.3127e-04 - val_loss: 9.2389e-09 - val_mse: 9.2389e-09 - val_mae: 9.5945e-05\n",
      "Epoch 99/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1741e-05 - mse: 2.1741e-05 - mae: 1.2149e-04 - val_loss: 1.4001e-08 - val_mse: 1.4001e-08 - val_mae: 1.1821e-04\n",
      "Epoch 100/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1742e-05 - mse: 2.1742e-05 - mae: 1.3555e-04 - val_loss: 1.1621e-08 - val_mse: 1.1621e-08 - val_mae: 1.0762e-04\n",
      "Epoch 101/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1719e-05 - mse: 2.1719e-05 - mae: 1.2479e-04 - val_loss: 1.0503e-08 - val_mse: 1.0503e-08 - val_mae: 1.0241e-04\n",
      "Epoch 102/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1717e-05 - mse: 2.1717e-05 - mae: 1.2100e-04 - val_loss: 1.0948e-08 - val_mse: 1.0948e-08 - val_mae: 1.0447e-04\n",
      "Epoch 103/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1707e-05 - mse: 2.1707e-05 - mae: 1.1985e-04 - val_loss: 4.1398e-09 - val_mse: 4.1398e-09 - val_mae: 6.4162e-05\n",
      "Epoch 104/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1678e-05 - mse: 2.1678e-05 - mae: 1.2568e-04 - val_loss: 1.5319e-08 - val_mse: 1.5319e-08 - val_mae: 1.2372e-04\n",
      "Epoch 105/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1686e-05 - mse: 2.1686e-05 - mae: 1.3055e-04 - val_loss: 1.3882e-08 - val_mse: 1.3882e-08 - val_mae: 1.1769e-04\n",
      "Epoch 106/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1677e-05 - mse: 2.1677e-05 - mae: 1.2388e-04 - val_loss: 1.0602e-08 - val_mse: 1.0602e-08 - val_mae: 1.0280e-04\n",
      "Epoch 107/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1657e-05 - mse: 2.1657e-05 - mae: 1.2371e-04 - val_loss: 1.2396e-08 - val_mse: 1.2396e-08 - val_mae: 1.1127e-04\n",
      "Epoch 108/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1653e-05 - mse: 2.1653e-05 - mae: 1.2121e-04 - val_loss: 1.0050e-08 - val_mse: 1.0050e-08 - val_mae: 1.0017e-04\n",
      "Epoch 109/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1647e-05 - mse: 2.1647e-05 - mae: 1.2700e-04 - val_loss: 1.0308e-08 - val_mse: 1.0308e-08 - val_mae: 1.0137e-04\n",
      "Epoch 110/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1635e-05 - mse: 2.1635e-05 - mae: 1.2448e-04 - val_loss: 6.4088e-09 - val_mse: 6.4088e-09 - val_mae: 7.9962e-05\n",
      "Epoch 111/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1637e-05 - mse: 2.1637e-05 - mae: 1.2488e-04 - val_loss: 1.4156e-08 - val_mse: 1.4156e-08 - val_mae: 1.1893e-04\n",
      "Epoch 112/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1632e-05 - mse: 2.1632e-05 - mae: 1.3203e-04 - val_loss: 1.4289e-08 - val_mse: 1.4289e-08 - val_mae: 1.1943e-04\n",
      "Epoch 113/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1606e-05 - mse: 2.1606e-05 - mae: 1.4015e-04 - val_loss: 4.5559e-10 - val_mse: 4.5559e-10 - val_mae: 2.0845e-05\n",
      "Epoch 114/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1619e-05 - mse: 2.1619e-05 - mae: 1.3729e-04 - val_loss: 4.9056e-11 - val_mse: 4.9056e-11 - val_mae: 2.6480e-06\n",
      "Epoch 115/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1576e-05 - mse: 2.1576e-05 - mae: 1.2137e-04 - val_loss: 9.4509e-09 - val_mse: 9.4509e-09 - val_mae: 9.7071e-05\n",
      "Epoch 116/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1590e-05 - mse: 2.1590e-05 - mae: 1.2018e-04 - val_loss: 1.0133e-08 - val_mse: 1.0133e-08 - val_mae: 1.0051e-04\n",
      "Epoch 117/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1577e-05 - mse: 2.1577e-05 - mae: 1.2431e-04 - val_loss: 1.0808e-08 - val_mse: 1.0808e-08 - val_mae: 1.0380e-04\n",
      "Epoch 118/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1568e-05 - mse: 2.1568e-05 - mae: 1.2351e-04 - val_loss: 1.7351e-08 - val_mse: 1.7351e-08 - val_mae: 1.3162e-04\n",
      "Epoch 119/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1555e-05 - mse: 2.1555e-05 - mae: 1.3547e-04 - val_loss: 1.2310e-08 - val_mse: 1.2310e-08 - val_mae: 1.1076e-04\n",
      "Epoch 120/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1546e-05 - mse: 2.1546e-05 - mae: 1.2225e-04 - val_loss: 4.9237e-08 - val_mse: 4.9237e-08 - val_mae: 2.2185e-04\n",
      "Epoch 121/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1527e-05 - mse: 2.1527e-05 - mae: 1.3403e-04 - val_loss: 1.2878e-08 - val_mse: 1.2878e-08 - val_mae: 1.1337e-04\n",
      "Epoch 122/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1517e-05 - mse: 2.1517e-05 - mae: 1.3929e-04 - val_loss: 3.0396e-11 - val_mse: 3.0396e-11 - val_mae: 2.9402e-06\n",
      "Epoch 123/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1508e-05 - mse: 2.1508e-05 - mae: 1.3478e-04 - val_loss: 2.1447e-08 - val_mse: 2.1447e-08 - val_mae: 1.4641e-04\n",
      "Epoch 124/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1515e-05 - mse: 2.1515e-05 - mae: 1.4192e-04 - val_loss: 4.7118e-08 - val_mse: 4.7118e-08 - val_mae: 2.1697e-04\n",
      "Epoch 125/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1507e-05 - mse: 2.1507e-05 - mae: 1.1993e-04 - val_loss: 9.8391e-09 - val_mse: 9.8391e-09 - val_mae: 9.9104e-05\n",
      "Epoch 126/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1494e-05 - mse: 2.1494e-05 - mae: 1.1981e-04 - val_loss: 4.5446e-09 - val_mse: 4.5446e-09 - val_mae: 6.7206e-05\n",
      "Epoch 127/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1484e-05 - mse: 2.1484e-05 - mae: 1.2107e-04 - val_loss: 2.6930e-11 - val_mse: 2.6930e-11 - val_mae: 2.3576e-06\n",
      "Epoch 128/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1478e-05 - mse: 2.1478e-05 - mae: 1.2751e-04 - val_loss: 6.9579e-11 - val_mse: 6.9579e-11 - val_mae: 2.5628e-06\n",
      "Epoch 129/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1437e-05 - mse: 2.1437e-05 - mae: 1.1479e-04 - val_loss: 1.0865e-08 - val_mse: 1.0865e-08 - val_mae: 1.0411e-04\n",
      "Epoch 130/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1466e-05 - mse: 2.1466e-05 - mae: 1.1552e-04 - val_loss: 5.9355e-09 - val_mse: 5.9355e-09 - val_mae: 7.6949e-05\n",
      "Epoch 131/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1454e-05 - mse: 2.1454e-05 - mae: 1.2044e-04 - val_loss: 1.3675e-09 - val_mse: 1.3675e-09 - val_mae: 3.6699e-05\n",
      "Epoch 132/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1452e-05 - mse: 2.1452e-05 - mae: 1.2327e-04 - val_loss: 4.2868e-09 - val_mse: 4.2868e-09 - val_mae: 6.5327e-05\n",
      "Epoch 133/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1425e-05 - mse: 2.1425e-05 - mae: 1.2335e-04 - val_loss: 9.3288e-09 - val_mse: 9.3288e-09 - val_mae: 9.6368e-05\n",
      "Epoch 134/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1413e-05 - mse: 2.1413e-05 - mae: 1.1667e-04 - val_loss: 9.5517e-09 - val_mse: 9.5517e-09 - val_mae: 9.7606e-05\n",
      "Epoch 135/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1419e-05 - mse: 2.1419e-05 - mae: 1.1944e-04 - val_loss: 9.3892e-09 - val_mse: 9.3892e-09 - val_mae: 9.6754e-05\n",
      "Epoch 136/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1409e-05 - mse: 2.1409e-05 - mae: 1.1909e-04 - val_loss: 5.3010e-11 - val_mse: 5.3010e-11 - val_mae: 2.5757e-06\n",
      "Epoch 137/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1396e-05 - mse: 2.1396e-05 - mae: 1.1792e-04 - val_loss: 7.7946e-09 - val_mse: 7.7946e-09 - val_mae: 8.8126e-05\n",
      "Epoch 138/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1395e-05 - mse: 2.1395e-05 - mae: 1.1962e-04 - val_loss: 7.9015e-09 - val_mse: 7.9015e-09 - val_mae: 8.8740e-05\n",
      "Epoch 139/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1382e-05 - mse: 2.1382e-05 - mae: 1.1827e-04 - val_loss: 9.2349e-09 - val_mse: 9.2349e-09 - val_mae: 9.5531e-05\n",
      "Epoch 140/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1362e-05 - mse: 2.1362e-05 - mae: 1.2098e-04 - val_loss: 2.9624e-11 - val_mse: 2.9624e-11 - val_mae: 2.6207e-06\n",
      "Epoch 141/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1369e-05 - mse: 2.1369e-05 - mae: 1.1347e-04 - val_loss: 8.4173e-09 - val_mse: 8.4173e-09 - val_mae: 9.1666e-05\n",
      "Epoch 142/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1361e-05 - mse: 2.1361e-05 - mae: 1.2006e-04 - val_loss: 9.9048e-09 - val_mse: 9.9048e-09 - val_mae: 9.9453e-05\n",
      "Epoch 143/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1345e-05 - mse: 2.1345e-05 - mae: 1.1675e-04 - val_loss: 8.9252e-09 - val_mse: 8.9252e-09 - val_mae: 9.4322e-05\n",
      "Epoch 144/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1346e-05 - mse: 2.1346e-05 - mae: 1.2183e-04 - val_loss: 8.7866e-09 - val_mse: 8.7866e-09 - val_mae: 9.3582e-05\n",
      "Epoch 145/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1332e-05 - mse: 2.1332e-05 - mae: 1.1622e-04 - val_loss: 8.4222e-09 - val_mse: 8.4222e-09 - val_mae: 9.1613e-05\n",
      "Epoch 146/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1327e-05 - mse: 2.1327e-05 - mae: 1.1362e-04 - val_loss: 9.4653e-09 - val_mse: 9.4653e-09 - val_mae: 9.7217e-05\n",
      "Epoch 147/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1310e-05 - mse: 2.1310e-05 - mae: 1.1695e-04 - val_loss: 9.5504e-09 - val_mse: 9.5504e-09 - val_mae: 9.7601e-05\n",
      "Epoch 148/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1304e-05 - mse: 2.1304e-05 - mae: 1.1798e-04 - val_loss: 9.6463e-09 - val_mse: 9.6463e-09 - val_mae: 9.8078e-05\n",
      "Epoch 149/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1285e-05 - mse: 2.1285e-05 - mae: 1.1920e-04 - val_loss: 7.1521e-11 - val_mse: 7.1521e-11 - val_mae: 2.9071e-06\n",
      "Epoch 150/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1266e-05 - mse: 2.1266e-05 - mae: 1.1527e-04 - val_loss: 3.9220e-10 - val_mse: 3.9220e-10 - val_mae: 1.9233e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53df65ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98ff6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=rms, loss='mse',  metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1944befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1611e-05 - mse: 2.1611e-05 - mae: 4.8507e-04 - val_loss: 2.4941e-07 - val_mse: 2.4941e-07 - val_mae: 4.9939e-04\n",
      "Epoch 2/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1470e-05 - mse: 2.1470e-05 - mae: 4.9159e-04 - val_loss: 2.5173e-07 - val_mse: 2.5173e-07 - val_mae: 5.0170e-04\n",
      "Epoch 3/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1325e-05 - mse: 2.1325e-05 - mae: 4.7475e-04 - val_loss: 2.4612e-07 - val_mse: 2.4612e-07 - val_mae: 4.9608e-04\n",
      "Epoch 4/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1319e-05 - mse: 2.1319e-05 - mae: 4.9437e-04 - val_loss: 2.5608e-07 - val_mse: 2.5608e-07 - val_mae: 5.0602e-04\n",
      "Epoch 5/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1176e-05 - mse: 2.1176e-05 - mae: 4.9028e-04 - val_loss: 6.3523e-07 - val_mse: 6.3523e-07 - val_mae: 7.9700e-04\n",
      "Epoch 6/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1099e-05 - mse: 2.1099e-05 - mae: 4.9150e-04 - val_loss: 2.5643e-07 - val_mse: 2.5643e-07 - val_mae: 5.0637e-04\n",
      "Epoch 7/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0985e-05 - mse: 2.0985e-05 - mae: 5.0530e-04 - val_loss: 2.5001e-07 - val_mse: 2.5001e-07 - val_mae: 4.9999e-04\n",
      "Epoch 8/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0876e-05 - mse: 2.0876e-05 - mae: 4.9050e-04 - val_loss: 2.4763e-07 - val_mse: 2.4763e-07 - val_mae: 4.9761e-04\n",
      "Epoch 9/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1055e-05 - mse: 2.1055e-05 - mae: 4.8546e-04 - val_loss: 2.4375e-07 - val_mse: 2.4375e-07 - val_mae: 4.9369e-04\n",
      "Epoch 10/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0896e-05 - mse: 2.0896e-05 - mae: 4.9166e-04 - val_loss: 2.5244e-07 - val_mse: 2.5244e-07 - val_mae: 5.0241e-04\n",
      "Epoch 11/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0638e-05 - mse: 2.0638e-05 - mae: 4.9785e-04 - val_loss: 2.3932e-07 - val_mse: 2.3932e-07 - val_mae: 4.8918e-04\n",
      "Epoch 12/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0405e-05 - mse: 2.0405e-05 - mae: 5.1125e-04 - val_loss: 2.5064e-07 - val_mse: 2.5064e-07 - val_mae: 5.0062e-04\n",
      "Epoch 13/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0364e-05 - mse: 2.0364e-05 - mae: 4.9428e-04 - val_loss: 2.6434e-07 - val_mse: 2.6434e-07 - val_mae: 5.1412e-04\n",
      "Epoch 14/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0191e-05 - mse: 2.0191e-05 - mae: 5.0177e-04 - val_loss: 2.5055e-07 - val_mse: 2.5055e-07 - val_mae: 5.0053e-04\n",
      "Epoch 15/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0143e-05 - mse: 2.0143e-05 - mae: 4.9105e-04 - val_loss: 2.5354e-07 - val_mse: 2.5354e-07 - val_mae: 5.0350e-04\n",
      "Epoch 16/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9938e-05 - mse: 1.9938e-05 - mae: 4.9509e-04 - val_loss: 2.0695e-07 - val_mse: 2.0695e-07 - val_mae: 4.5489e-04\n",
      "Epoch 17/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9790e-05 - mse: 1.9790e-05 - mae: 4.9660e-04 - val_loss: 2.6210e-07 - val_mse: 2.6210e-07 - val_mae: 5.1194e-04\n",
      "Epoch 18/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.0033e-05 - mse: 2.0033e-05 - mae: 4.8282e-04 - val_loss: 2.5097e-07 - val_mse: 2.5097e-07 - val_mae: 5.0095e-04\n",
      "Epoch 19/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9542e-05 - mse: 1.9542e-05 - mae: 4.9630e-04 - val_loss: 3.7282e-10 - val_mse: 3.7282e-10 - val_mae: 1.8856e-05\n",
      "Epoch 20/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9771e-05 - mse: 1.9771e-05 - mae: 5.0885e-04 - val_loss: 2.5037e-07 - val_mse: 2.5037e-07 - val_mae: 5.0035e-04\n",
      "Epoch 21/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9339e-05 - mse: 1.9339e-05 - mae: 4.9699e-04 - val_loss: 2.4977e-07 - val_mse: 2.4977e-07 - val_mae: 4.9975e-04\n",
      "Epoch 22/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9183e-05 - mse: 1.9183e-05 - mae: 4.9928e-04 - val_loss: 2.5142e-07 - val_mse: 2.5142e-07 - val_mae: 5.0140e-04\n",
      "Epoch 23/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.9063e-05 - mse: 1.9063e-05 - mae: 4.8933e-04 - val_loss: 3.0515e-07 - val_mse: 3.0515e-07 - val_mae: 5.5238e-04\n",
      "Epoch 24/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8967e-05 - mse: 1.8967e-05 - mae: 4.8634e-04 - val_loss: 2.4961e-07 - val_mse: 2.4961e-07 - val_mae: 4.9959e-04\n",
      "Epoch 25/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8777e-05 - mse: 1.8777e-05 - mae: 4.9776e-04 - val_loss: 1.3123e-08 - val_mse: 1.3123e-08 - val_mae: 1.1447e-04\n",
      "Epoch 26/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8652e-05 - mse: 1.8652e-05 - mae: 4.9230e-04 - val_loss: 2.0357e-07 - val_mse: 2.0357e-07 - val_mae: 4.5116e-04\n",
      "Epoch 27/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8745e-05 - mse: 1.8745e-05 - mae: 4.9273e-04 - val_loss: 2.4868e-07 - val_mse: 2.4868e-07 - val_mae: 4.9866e-04\n",
      "Epoch 28/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8846e-05 - mse: 1.8846e-05 - mae: 4.9260e-04 - val_loss: 3.9200e-07 - val_mse: 3.9200e-07 - val_mae: 6.2608e-04\n",
      "Epoch 29/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8299e-05 - mse: 1.8299e-05 - mae: 4.8651e-04 - val_loss: 2.5072e-07 - val_mse: 2.5072e-07 - val_mae: 5.0070e-04\n",
      "Epoch 30/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8327e-05 - mse: 1.8327e-05 - mae: 5.0195e-04 - val_loss: 2.5111e-07 - val_mse: 2.5111e-07 - val_mae: 5.0109e-04\n",
      "Epoch 31/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8090e-05 - mse: 1.8090e-05 - mae: 4.8808e-04 - val_loss: 2.5028e-07 - val_mse: 2.5028e-07 - val_mae: 5.0026e-04\n",
      "Epoch 32/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8257e-05 - mse: 1.8257e-05 - mae: 4.9880e-04 - val_loss: 2.5065e-07 - val_mse: 2.5065e-07 - val_mae: 5.0063e-04\n",
      "Epoch 33/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8133e-05 - mse: 1.8133e-05 - mae: 5.0352e-04 - val_loss: 2.5230e-07 - val_mse: 2.5230e-07 - val_mae: 5.0228e-04\n",
      "Epoch 34/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.8183e-05 - mse: 1.8183e-05 - mae: 4.8348e-04 - val_loss: 1.1542e-08 - val_mse: 1.1542e-08 - val_mae: 1.0727e-04\n",
      "Epoch 35/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7773e-05 - mse: 1.7773e-05 - mae: 4.7955e-04 - val_loss: 2.5009e-07 - val_mse: 2.5009e-07 - val_mae: 5.0007e-04\n",
      "Epoch 36/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7602e-05 - mse: 1.7602e-05 - mae: 5.0072e-04 - val_loss: 3.4575e-07 - val_mse: 3.4575e-07 - val_mae: 5.8596e-04\n",
      "Epoch 37/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7345e-05 - mse: 1.7345e-05 - mae: 5.0398e-04 - val_loss: 2.5238e-07 - val_mse: 2.5238e-07 - val_mae: 5.0235e-04\n",
      "Epoch 38/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7252e-05 - mse: 1.7252e-05 - mae: 4.8125e-04 - val_loss: 2.3660e-07 - val_mse: 2.3660e-07 - val_mae: 4.8640e-04\n",
      "Epoch 39/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7522e-05 - mse: 1.7522e-05 - mae: 4.8996e-04 - val_loss: 3.9891e-08 - val_mse: 3.9891e-08 - val_mae: 1.9970e-04\n",
      "Epoch 40/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7170e-05 - mse: 1.7170e-05 - mae: 4.8564e-04 - val_loss: 2.5037e-07 - val_mse: 2.5037e-07 - val_mae: 5.0034e-04\n",
      "Epoch 41/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7194e-05 - mse: 1.7194e-05 - mae: 4.9148e-04 - val_loss: 2.5116e-07 - val_mse: 2.5116e-07 - val_mae: 5.0114e-04\n",
      "Epoch 42/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6812e-05 - mse: 1.6812e-05 - mae: 4.8935e-04 - val_loss: 1.3626e-07 - val_mse: 1.3626e-07 - val_mae: 3.6909e-04\n",
      "Epoch 43/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6584e-05 - mse: 1.6584e-05 - mae: 4.9203e-04 - val_loss: 2.5117e-07 - val_mse: 2.5117e-07 - val_mae: 5.0115e-04\n",
      "Epoch 44/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6500e-05 - mse: 1.6500e-05 - mae: 4.9957e-04 - val_loss: 4.7806e-08 - val_mse: 4.7806e-08 - val_mae: 2.1862e-04\n",
      "Epoch 45/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6400e-05 - mse: 1.6400e-05 - mae: 4.7988e-04 - val_loss: 1.3686e-08 - val_mse: 1.3686e-08 - val_mae: 1.1690e-04\n",
      "Epoch 46/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6538e-05 - mse: 1.6538e-05 - mae: 4.8712e-04 - val_loss: 1.8689e-07 - val_mse: 1.8689e-07 - val_mae: 4.2991e-04\n",
      "Epoch 47/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6341e-05 - mse: 1.6341e-05 - mae: 5.1529e-04 - val_loss: 2.2981e-07 - val_mse: 2.2981e-07 - val_mae: 4.7780e-04\n",
      "Epoch 48/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6142e-05 - mse: 1.6142e-05 - mae: 4.7980e-04 - val_loss: 2.3992e-07 - val_mse: 2.3992e-07 - val_mae: 4.8962e-04\n",
      "Epoch 49/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6282e-05 - mse: 1.6282e-05 - mae: 4.9448e-04 - val_loss: 2.5237e-07 - val_mse: 2.5237e-07 - val_mae: 5.0235e-04\n",
      "Epoch 50/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6152e-05 - mse: 1.6152e-05 - mae: 4.8735e-04 - val_loss: 2.4590e-07 - val_mse: 2.4590e-07 - val_mae: 4.9586e-04\n",
      "Epoch 51/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6023e-05 - mse: 1.6023e-05 - mae: 4.8871e-04 - val_loss: 2.4925e-07 - val_mse: 2.4925e-07 - val_mae: 4.9923e-04\n",
      "Epoch 52/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.5449e-05 - mse: 1.5449e-05 - mae: 4.8819e-04 - val_loss: 2.5203e-07 - val_mse: 2.5203e-07 - val_mae: 5.0201e-04\n",
      "Epoch 53/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.5143e-05 - mse: 1.5143e-05 - mae: 4.8375e-04 - val_loss: 2.0175e-07 - val_mse: 2.0175e-07 - val_mae: 4.4914e-04\n",
      "Epoch 54/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.5157e-05 - mse: 1.5157e-05 - mae: 4.9961e-04 - val_loss: 2.1702e-11 - val_mse: 2.1702e-11 - val_mae: 2.3001e-06\n",
      "Epoch 55/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.4782e-05 - mse: 1.4782e-05 - mae: 4.7841e-04 - val_loss: 2.5169e-07 - val_mse: 2.5169e-07 - val_mae: 5.0166e-04\n",
      "Epoch 56/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.5249e-05 - mse: 1.5249e-05 - mae: 4.9348e-04 - val_loss: 2.4743e-07 - val_mse: 2.4743e-07 - val_mae: 4.9740e-04\n",
      "Epoch 57/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.5004e-05 - mse: 1.5004e-05 - mae: 4.8849e-04 - val_loss: 1.8474e-07 - val_mse: 1.8474e-07 - val_mae: 4.2979e-04\n",
      "Epoch 58/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.4560e-05 - mse: 1.4560e-05 - mae: 4.9116e-04 - val_loss: 2.4744e-07 - val_mse: 2.4744e-07 - val_mae: 4.9741e-04\n",
      "Epoch 59/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.4658e-05 - mse: 1.4658e-05 - mae: 5.0047e-04 - val_loss: 2.4013e-09 - val_mse: 2.4013e-09 - val_mae: 3.5911e-06\n",
      "Epoch 60/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3783e-05 - mse: 1.3783e-05 - mae: 4.8877e-04 - val_loss: 2.4555e-07 - val_mse: 2.4555e-07 - val_mae: 4.9551e-04\n",
      "Epoch 61/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3772e-05 - mse: 1.3772e-05 - mae: 5.1674e-04 - val_loss: 4.4082e-06 - val_mse: 4.4082e-06 - val_mae: 0.0016\n",
      "Epoch 62/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3532e-05 - mse: 1.3532e-05 - mae: 4.7277e-04 - val_loss: 2.7240e-07 - val_mse: 2.7240e-07 - val_mae: 5.1926e-04\n",
      "Epoch 63/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3890e-05 - mse: 1.3890e-05 - mae: 4.9610e-04 - val_loss: 2.4212e-07 - val_mse: 2.4212e-07 - val_mae: 4.9204e-04\n",
      "Epoch 64/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3304e-05 - mse: 1.3304e-05 - mae: 4.8170e-04 - val_loss: 2.5226e-07 - val_mse: 2.5226e-07 - val_mae: 5.0224e-04\n",
      "Epoch 65/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3262e-05 - mse: 1.3262e-05 - mae: 4.8931e-04 - val_loss: 2.3519e-07 - val_mse: 2.3519e-07 - val_mae: 4.8495e-04\n",
      "Epoch 66/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3365e-05 - mse: 1.3365e-05 - mae: 4.9008e-04 - val_loss: 2.4864e-07 - val_mse: 2.4864e-07 - val_mae: 4.9862e-04\n",
      "Epoch 67/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.3071e-05 - mse: 1.3071e-05 - mae: 4.8696e-04 - val_loss: 2.5469e-07 - val_mse: 2.5469e-07 - val_mae: 5.0465e-04\n",
      "Epoch 68/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.2544e-05 - mse: 1.2544e-05 - mae: 4.8633e-04 - val_loss: 2.5424e-07 - val_mse: 2.5424e-07 - val_mae: 5.0420e-04\n",
      "Epoch 69/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.2709e-05 - mse: 1.2709e-05 - mae: 4.9863e-04 - val_loss: 2.2428e-08 - val_mse: 2.2428e-08 - val_mae: 3.8328e-05\n",
      "Epoch 70/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.2205e-05 - mse: 1.2205e-05 - mae: 4.9350e-04 - val_loss: 2.4360e-07 - val_mse: 2.4360e-07 - val_mae: 4.9354e-04\n",
      "Epoch 71/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1957e-05 - mse: 1.1957e-05 - mae: 5.0032e-04 - val_loss: 2.5117e-07 - val_mse: 2.5117e-07 - val_mae: 5.0115e-04\n",
      "Epoch 72/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1810e-05 - mse: 1.1810e-05 - mae: 4.8658e-04 - val_loss: 2.4005e-07 - val_mse: 2.4005e-07 - val_mae: 4.8993e-04\n",
      "Epoch 73/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1925e-05 - mse: 1.1925e-05 - mae: 4.8798e-04 - val_loss: 2.5218e-07 - val_mse: 2.5218e-07 - val_mae: 5.0216e-04\n",
      "Epoch 74/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1513e-05 - mse: 1.1513e-05 - mae: 4.8291e-04 - val_loss: 2.5134e-07 - val_mse: 2.5134e-07 - val_mae: 5.0132e-04\n",
      "Epoch 75/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1326e-05 - mse: 1.1326e-05 - mae: 5.1300e-04 - val_loss: 2.4702e-07 - val_mse: 2.4702e-07 - val_mae: 4.9699e-04\n",
      "Epoch 76/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1099e-05 - mse: 1.1099e-05 - mae: 4.9597e-04 - val_loss: 2.0074e-11 - val_mse: 2.0074e-11 - val_mae: 2.3649e-06\n",
      "Epoch 77/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.0839e-05 - mse: 1.0839e-05 - mae: 4.7767e-04 - val_loss: 4.1087e-07 - val_mse: 4.1087e-07 - val_mae: 6.4097e-04\n",
      "Epoch 78/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1178e-05 - mse: 1.1178e-05 - mae: 4.7242e-04 - val_loss: 2.4980e-07 - val_mse: 2.4980e-07 - val_mae: 4.9978e-04\n",
      "Epoch 79/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.0234e-05 - mse: 1.0234e-05 - mae: 5.1077e-04 - val_loss: 1.7602e-07 - val_mse: 1.7602e-07 - val_mae: 4.1952e-04\n",
      "Epoch 80/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.0268e-05 - mse: 1.0268e-05 - mae: 4.8423e-04 - val_loss: 2.4806e-07 - val_mse: 2.4806e-07 - val_mae: 4.9804e-04\n",
      "Epoch 81/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.0145e-05 - mse: 1.0145e-05 - mae: 4.8973e-04 - val_loss: 2.4878e-07 - val_mse: 2.4878e-07 - val_mae: 4.9876e-04\n",
      "Epoch 82/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 9.7010e-06 - mse: 9.7010e-06 - mae: 4.7790e-04 - val_loss: 2.4426e-07 - val_mse: 2.4426e-07 - val_mae: 4.9421e-04\n",
      "Epoch 83/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 9.3664e-06 - mse: 9.3664e-06 - mae: 4.9520e-04 - val_loss: 2.5173e-07 - val_mse: 2.5173e-07 - val_mae: 5.0170e-04\n",
      "Epoch 84/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 9.5601e-06 - mse: 9.5601e-06 - mae: 4.7060e-04 - val_loss: 2.4826e-07 - val_mse: 2.4826e-07 - val_mae: 4.9824e-04\n",
      "Epoch 85/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 8.9229e-06 - mse: 8.9229e-06 - mae: 4.7479e-04 - val_loss: 2.4418e-07 - val_mse: 2.4418e-07 - val_mae: 4.9413e-04\n",
      "Epoch 86/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 8.3603e-06 - mse: 8.3603e-06 - mae: 4.8107e-04 - val_loss: 2.5367e-07 - val_mse: 2.5367e-07 - val_mae: 5.0364e-04\n",
      "Epoch 87/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 8.2838e-06 - mse: 8.2838e-06 - mae: 4.8764e-04 - val_loss: 2.3950e-10 - val_mse: 2.3950e-10 - val_mae: 1.4806e-05\n",
      "Epoch 88/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 6.9766e-06 - mse: 6.9766e-06 - mae: 4.7140e-04 - val_loss: 2.4881e-07 - val_mse: 2.4881e-07 - val_mae: 4.9878e-04\n",
      "Epoch 89/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 7.0582e-06 - mse: 7.0582e-06 - mae: 4.7974e-04 - val_loss: 1.9583e-07 - val_mse: 1.9583e-07 - val_mae: 4.4250e-04\n",
      "Epoch 90/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 6.8972e-06 - mse: 6.8972e-06 - mae: 4.8833e-04 - val_loss: 2.3053e-07 - val_mse: 2.3053e-07 - val_mae: 4.8011e-04\n",
      "Epoch 91/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.8110e-06 - mse: 5.8110e-06 - mae: 4.9200e-04 - val_loss: 2.4991e-07 - val_mse: 2.4991e-07 - val_mae: 4.9989e-04\n",
      "Epoch 92/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.6217e-06 - mse: 5.6217e-06 - mae: 4.9005e-04 - val_loss: 1.0944e-07 - val_mse: 1.0944e-07 - val_mae: 3.1954e-04\n",
      "Epoch 93/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.8771e-06 - mse: 4.8771e-06 - mae: 4.8160e-04 - val_loss: 2.4299e-07 - val_mse: 2.4299e-07 - val_mae: 4.9292e-04\n",
      "Epoch 94/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.9515e-06 - mse: 4.9515e-06 - mae: 4.7861e-04 - val_loss: 2.4649e-07 - val_mse: 2.4649e-07 - val_mae: 4.9646e-04\n",
      "Epoch 95/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.6641e-06 - mse: 4.6641e-06 - mae: 4.8913e-04 - val_loss: 2.4085e-07 - val_mse: 2.4085e-07 - val_mae: 4.9075e-04\n",
      "Epoch 96/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.1961e-06 - mse: 4.1961e-06 - mae: 4.8493e-04 - val_loss: 2.5339e-07 - val_mse: 2.5339e-07 - val_mae: 5.0336e-04\n",
      "Epoch 97/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.7343e-06 - mse: 3.7343e-06 - mae: 4.8308e-04 - val_loss: 2.5225e-07 - val_mse: 2.5225e-07 - val_mae: 5.0223e-04\n",
      "Epoch 98/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.4521e-06 - mse: 3.4521e-06 - mae: 4.8864e-04 - val_loss: 1.5022e-07 - val_mse: 1.5022e-07 - val_mae: 3.7923e-04\n",
      "Epoch 99/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.8981e-06 - mse: 2.8981e-06 - mae: 4.8271e-04 - val_loss: 2.4913e-07 - val_mse: 2.4913e-07 - val_mae: 4.9911e-04\n",
      "Epoch 100/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.7277e-06 - mse: 2.7277e-06 - mae: 4.7490e-04 - val_loss: 2.5125e-07 - val_mse: 2.5125e-07 - val_mae: 5.0122e-04\n",
      "Epoch 101/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.6444e-06 - mse: 2.6444e-06 - mae: 4.7971e-04 - val_loss: 2.5008e-07 - val_mse: 2.5008e-07 - val_mae: 5.0006e-04\n",
      "Epoch 102/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.1098e-06 - mse: 2.1098e-06 - mae: 4.8290e-04 - val_loss: 2.4156e-07 - val_mse: 2.4156e-07 - val_mae: 4.9147e-04\n",
      "Epoch 103/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.3750e-06 - mse: 2.3750e-06 - mae: 4.7450e-04 - val_loss: 2.4174e-07 - val_mse: 2.4174e-07 - val_mae: 4.9096e-04\n",
      "Epoch 104/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 2.2998e-06 - mse: 2.2998e-06 - mae: 4.6782e-04 - val_loss: 2.5298e-07 - val_mse: 2.5298e-07 - val_mae: 5.0294e-04\n",
      "Epoch 105/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.7029e-06 - mse: 1.7029e-06 - mae: 4.7875e-04 - val_loss: 1.6027e-07 - val_mse: 1.6027e-07 - val_mae: 4.0032e-04\n",
      "Epoch 106/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6160e-06 - mse: 1.6160e-06 - mae: 4.7479e-04 - val_loss: 2.4790e-07 - val_mse: 2.4790e-07 - val_mae: 4.9788e-04\n",
      "Epoch 107/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.6187e-06 - mse: 1.6187e-06 - mae: 4.7478e-04 - val_loss: 3.9956e-07 - val_mse: 3.9956e-07 - val_mae: 6.3209e-04\n",
      "Epoch 108/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1932e-06 - mse: 1.1932e-06 - mae: 4.8955e-04 - val_loss: 2.4801e-07 - val_mse: 2.4801e-07 - val_mae: 4.9798e-04\n",
      "Epoch 109/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.1073e-06 - mse: 1.1073e-06 - mae: 4.7642e-04 - val_loss: 2.5816e-07 - val_mse: 2.5816e-07 - val_mae: 5.0808e-04\n",
      "Epoch 110/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 1.0242e-06 - mse: 1.0242e-06 - mae: 4.6823e-04 - val_loss: 6.9785e-07 - val_mse: 6.9785e-07 - val_mae: 8.3536e-04\n",
      "Epoch 111/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.6843e-07 - mse: 5.6843e-07 - mae: 4.9160e-04 - val_loss: 2.5233e-07 - val_mse: 2.5233e-07 - val_mae: 5.0231e-04\n",
      "Epoch 112/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 6.4795e-07 - mse: 6.4795e-07 - mae: 4.7519e-04 - val_loss: 2.4830e-07 - val_mse: 2.4830e-07 - val_mae: 4.9828e-04\n",
      "Epoch 113/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.9222e-07 - mse: 5.9222e-07 - mae: 4.8304e-04 - val_loss: 6.9803e-09 - val_mse: 6.9803e-09 - val_mae: 6.2058e-05\n",
      "Epoch 114/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.7051e-07 - mse: 4.7051e-07 - mae: 4.7152e-04 - val_loss: 2.5247e-07 - val_mse: 2.5247e-07 - val_mae: 5.0244e-04\n",
      "Epoch 115/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.7499e-07 - mse: 4.7499e-07 - mae: 4.8888e-04 - val_loss: 2.5222e-07 - val_mse: 2.5222e-07 - val_mae: 5.0220e-04\n",
      "Epoch 116/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.2173e-07 - mse: 4.2173e-07 - mae: 4.7598e-04 - val_loss: 2.3278e-07 - val_mse: 2.3278e-07 - val_mae: 4.8245e-04\n",
      "Epoch 117/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.9990e-07 - mse: 4.9990e-07 - mae: 4.7889e-04 - val_loss: 2.0574e-07 - val_mse: 2.0574e-07 - val_mae: 4.5356e-04\n",
      "Epoch 118/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.7185e-07 - mse: 4.7185e-07 - mae: 4.8109e-04 - val_loss: 2.4722e-07 - val_mse: 2.4722e-07 - val_mae: 4.9720e-04\n",
      "Epoch 119/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.4686e-07 - mse: 4.4686e-07 - mae: 4.7965e-04 - val_loss: 2.4416e-07 - val_mse: 2.4416e-07 - val_mae: 4.9410e-04\n",
      "Epoch 120/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.5588e-07 - mse: 3.5588e-07 - mae: 4.8400e-04 - val_loss: 2.5068e-07 - val_mse: 2.5068e-07 - val_mae: 5.0066e-04\n",
      "Epoch 121/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.6022e-07 - mse: 4.6022e-07 - mae: 4.8975e-04 - val_loss: 2.4942e-07 - val_mse: 2.4942e-07 - val_mae: 4.9940e-04\n",
      "Epoch 122/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.3329e-07 - mse: 4.3329e-07 - mae: 4.8565e-04 - val_loss: 2.4879e-07 - val_mse: 2.4879e-07 - val_mae: 4.9877e-04\n",
      "Epoch 123/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.1225e-07 - mse: 4.1225e-07 - mae: 4.9440e-04 - val_loss: 2.5088e-07 - val_mse: 2.5088e-07 - val_mae: 5.0086e-04\n",
      "Epoch 124/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.5297e-07 - mse: 3.5297e-07 - mae: 4.8348e-04 - val_loss: 2.7331e-07 - val_mse: 2.7331e-07 - val_mae: 5.2277e-04\n",
      "Epoch 125/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.8722e-07 - mse: 3.8722e-07 - mae: 4.8292e-04 - val_loss: 2.5273e-07 - val_mse: 2.5273e-07 - val_mae: 5.0270e-04\n",
      "Epoch 126/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.4516e-07 - mse: 3.4516e-07 - mae: 4.9480e-04 - val_loss: 2.4973e-07 - val_mse: 2.4973e-07 - val_mae: 4.9971e-04\n",
      "Epoch 127/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.9101e-07 - mse: 4.9101e-07 - mae: 4.7489e-04 - val_loss: 1.6036e-07 - val_mse: 1.6036e-07 - val_mae: 4.0042e-04\n",
      "Epoch 128/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.1035e-07 - mse: 5.1035e-07 - mae: 4.8468e-04 - val_loss: 2.5595e-07 - val_mse: 2.5595e-07 - val_mae: 5.0590e-04\n",
      "Epoch 129/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.8387e-07 - mse: 4.8387e-07 - mae: 4.8529e-04 - val_loss: 1.2681e-07 - val_mse: 1.2681e-07 - val_mae: 3.5607e-04\n",
      "Epoch 130/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.4519e-07 - mse: 3.4519e-07 - mae: 4.9514e-04 - val_loss: 3.3233e-07 - val_mse: 3.3233e-07 - val_mae: 5.7646e-04\n",
      "Epoch 131/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.5198e-07 - mse: 3.5198e-07 - mae: 4.8258e-04 - val_loss: 2.6163e-07 - val_mse: 2.6163e-07 - val_mae: 5.1148e-04\n",
      "Epoch 132/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.2226e-07 - mse: 4.2226e-07 - mae: 4.8646e-04 - val_loss: 2.5183e-07 - val_mse: 2.5183e-07 - val_mae: 5.0181e-04\n",
      "Epoch 133/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.4649e-07 - mse: 3.4649e-07 - mae: 4.8364e-04 - val_loss: 2.4947e-07 - val_mse: 2.4947e-07 - val_mae: 4.9945e-04\n",
      "Epoch 134/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.4607e-07 - mse: 3.4607e-07 - mae: 4.8998e-04 - val_loss: 2.7036e-07 - val_mse: 2.7036e-07 - val_mae: 5.1994e-04\n",
      "Epoch 135/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.5743e-07 - mse: 3.5743e-07 - mae: 4.9240e-04 - val_loss: 2.5077e-07 - val_mse: 2.5077e-07 - val_mae: 5.0075e-04\n",
      "Epoch 136/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.1642e-07 - mse: 5.1642e-07 - mae: 4.8149e-04 - val_loss: 2.5057e-07 - val_mse: 2.5057e-07 - val_mae: 5.0055e-04\n",
      "Epoch 137/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.2008e-07 - mse: 4.2008e-07 - mae: 4.8601e-04 - val_loss: 4.0186e-10 - val_mse: 4.0186e-10 - val_mae: 1.9612e-05\n",
      "Epoch 138/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 5.1647e-07 - mse: 5.1647e-07 - mae: 4.7839e-04 - val_loss: 2.7989e-09 - val_mse: 2.7989e-09 - val_mae: 5.2761e-05\n",
      "Epoch 139/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.6482e-07 - mse: 3.6482e-07 - mae: 4.7598e-04 - val_loss: 2.4815e-07 - val_mse: 2.4815e-07 - val_mae: 4.9813e-04\n",
      "Epoch 140/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.5628e-07 - mse: 4.5628e-07 - mae: 4.8772e-04 - val_loss: 8.2722e-08 - val_mse: 8.2722e-08 - val_mae: 2.8758e-04\n",
      "Epoch 141/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.3151e-07 - mse: 4.3151e-07 - mae: 4.7610e-04 - val_loss: 2.4925e-07 - val_mse: 2.4925e-07 - val_mae: 4.9922e-04\n",
      "Epoch 142/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.1491e-07 - mse: 4.1491e-07 - mae: 4.8480e-04 - val_loss: 2.6427e-07 - val_mse: 2.6427e-07 - val_mae: 5.1406e-04\n",
      "Epoch 143/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.1889e-07 - mse: 4.1889e-07 - mae: 4.9195e-04 - val_loss: 2.6303e-07 - val_mse: 2.6303e-07 - val_mae: 5.1284e-04\n",
      "Epoch 144/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.7170e-07 - mse: 3.7170e-07 - mae: 4.9513e-04 - val_loss: 2.4830e-07 - val_mse: 2.4830e-07 - val_mae: 4.9828e-04\n",
      "Epoch 145/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 4.0154e-07 - mse: 4.0154e-07 - mae: 4.8605e-04 - val_loss: 5.0887e-08 - val_mse: 5.0887e-08 - val_mae: 2.2555e-04\n",
      "Epoch 146/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.8497e-07 - mse: 3.8497e-07 - mae: 4.8736e-04 - val_loss: 2.7187e-07 - val_mse: 2.7187e-07 - val_mae: 5.2139e-04\n",
      "Epoch 147/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.8257e-07 - mse: 3.8257e-07 - mae: 4.9093e-04 - val_loss: 8.2544e-08 - val_mse: 8.2544e-08 - val_mae: 2.8727e-04\n",
      "Epoch 148/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.7193e-07 - mse: 3.7193e-07 - mae: 4.9101e-04 - val_loss: 2.5271e-07 - val_mse: 2.5271e-07 - val_mae: 5.0268e-04\n",
      "Epoch 149/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.6359e-07 - mse: 3.6359e-07 - mae: 4.9165e-04 - val_loss: 3.7601e-07 - val_mse: 3.7601e-07 - val_mae: 6.1318e-04\n",
      "Epoch 150/150\n",
      "972/972 [==============================] - 3s 3ms/step - loss: 3.5779e-07 - mse: 3.5779e-07 - mae: 4.9268e-04 - val_loss: 2.4947e-07 - val_mse: 2.4947e-07 - val_mae: 4.9945e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fef44863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a0f6cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                180       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293\n",
      "Trainable params: 293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dense/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Gabriel\\AppData\\Local\\Temp/ipykernel_25516/2803122240.py\", line 8, in <module>\n      history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/dense/MatMul'\nMatrix size-incompatible: In[0]: [50,3], In[1]: [14,12]\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_train_function_1830287]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25516/2803122240.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dense/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\Gabriel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Gabriel\\AppData\\Local\\Temp/ipykernel_25516/2803122240.py\", line 8, in <module>\n      history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Gabriel\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\core\\dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/dense/MatMul'\nMatrix size-incompatible: In[0]: [50,3], In[1]: [14,12]\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_train_function_1830287]"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "#data_A input dimension = 14\n",
    "model2.add(Dense(12, input_dim=14, kernel_initializer='normal', activation='sigmoid'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "model2.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f6009aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25516/634159832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3158\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   3161\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a44111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
